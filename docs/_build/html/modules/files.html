

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tensorlayer.files &mdash; TensorLayer 1.1 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="TensorLayer 1.1 documentation" href="../index.html"/>
        <link rel="next" title="tensorlayer.utils" href="utils.html"/>
        <link rel="prev" title="tensorlayer.visualize" href="visualize.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> TensorLayer
          

          
          </a>

          
            
            
              <div class="version">
                1.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../user/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user/tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user/layers.html">Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user/development.html">Development</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="layers.html"><code class="docutils literal"><span class="pre">tensorlayer.layers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="activation.html"><code class="docutils literal"><span class="pre">tensorlayer.activation</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html"><code class="docutils literal"><span class="pre">tensorlayer.nlp</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="rein.html"><code class="docutils literal"><span class="pre">tensorlayer.rein</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="iterate.html"><code class="docutils literal"><span class="pre">tensorlayer.iterate</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="cost.html"><code class="docutils literal"><span class="pre">tensorlayer.cost</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="visualize.html"><code class="docutils literal"><span class="pre">tensorlayer.visualize</span></code></a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#"><code class="docutils literal"><span class="pre">tensorlayer.files</span></code></a><ul>
<li class="toctree-l2"><a class="reference internal" href="#load-dataset-functions">Load dataset functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#vector-representations-of-words">Vector representations of words</a></li>
<li class="toctree-l2"><a class="reference internal" href="#load-and-save-network">Load and save network</a></li>
<li class="toctree-l2"><a class="reference internal" href="#load-and-save-variables">Load and save variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="#visualizing-npz-file">Visualizing npz file</a></li>
<li class="toctree-l2"><a class="reference internal" href="#helper-functions">Helper functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="utils.html"><code class="docutils literal"><span class="pre">tensorlayer.utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="init.html"><code class="docutils literal"><span class="pre">tensorlayer.init</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="preprocess.html"><code class="docutils literal"><span class="pre">tensorlayer.preprocess</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="os.html"><code class="docutils literal"><span class="pre">tensorlayer.os</span></code></a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">TensorLayer</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
    <li><code class="docutils literal"><span class="pre">tensorlayer.files</span></code></li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/modules/files.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-tensorlayer.files">
<span id="tensorlayer-files"></span><h1><a class="reference internal" href="#module-tensorlayer.files" title="tensorlayer.files"><code class="xref py py-mod docutils literal"><span class="pre">tensorlayer.files</span></code></a><a class="headerlink" href="#module-tensorlayer.files" title="Permalink to this headline">¶</a></h1>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#tensorlayer.files.load_mnist_dataset" title="tensorlayer.files.load_mnist_dataset"><code class="xref py py-obj docutils literal"><span class="pre">load_mnist_dataset</span></code></a>([shape])</td>
<td>Automatically download MNIST dataset and return the training, validation and test set with 50000, 10000 and 10000 digit images respectively.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#tensorlayer.files.load_cifar10_dataset" title="tensorlayer.files.load_cifar10_dataset"><code class="xref py py-obj docutils literal"><span class="pre">load_cifar10_dataset</span></code></a>([shape,&nbsp;plotable,&nbsp;second])</td>
<td>The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#tensorlayer.files.load_ptb_dataset" title="tensorlayer.files.load_ptb_dataset"><code class="xref py py-obj docutils literal"><span class="pre">load_ptb_dataset</span></code></a>()</td>
<td>PTB dataset is used in many LM papers, including &#8220;Empirical Evaluation and Combination of Advanced Language Modeling Techniques&#8221;.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#tensorlayer.files.load_matt_mahoney_text8_dataset" title="tensorlayer.files.load_matt_mahoney_text8_dataset"><code class="xref py py-obj docutils literal"><span class="pre">load_matt_mahoney_text8_dataset</span></code></a>()</td>
<td>Download a text file from Matt Mahoney&#8217;s website if not present, and make sure it&#8217;s the right size.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#tensorlayer.files.load_imbd_dataset" title="tensorlayer.files.load_imbd_dataset"><code class="xref py py-obj docutils literal"><span class="pre">load_imbd_dataset</span></code></a>([path,&nbsp;nb_words,&nbsp;...])</td>
<td>Load IMDB dataset</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#tensorlayer.files.read_words" title="tensorlayer.files.read_words"><code class="xref py py-obj docutils literal"><span class="pre">read_words</span></code></a>(filename)</td>
<td>File to list format context.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#tensorlayer.files.read_analogies_file" title="tensorlayer.files.read_analogies_file"><code class="xref py py-obj docutils literal"><span class="pre">read_analogies_file</span></code></a>([eval_file,&nbsp;word2id])</td>
<td>Reads through an analogy question file, return its id format.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#tensorlayer.files.build_vocab" title="tensorlayer.files.build_vocab"><code class="xref py py-obj docutils literal"><span class="pre">build_vocab</span></code></a>(data)</td>
<td>Build vocabulary.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#tensorlayer.files.build_reverse_dictionary" title="tensorlayer.files.build_reverse_dictionary"><code class="xref py py-obj docutils literal"><span class="pre">build_reverse_dictionary</span></code></a>(word_to_id)</td>
<td>Given a dictionary for converting word to integer id.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#tensorlayer.files.build_words_dataset" title="tensorlayer.files.build_words_dataset"><code class="xref py py-obj docutils literal"><span class="pre">build_words_dataset</span></code></a>(words[,&nbsp;...])</td>
<td>Build the words dictionary and replace rare words with &#8216;UNK&#8217; token.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#tensorlayer.files.words_to_word_ids" title="tensorlayer.files.words_to_word_ids"><code class="xref py py-obj docutils literal"><span class="pre">words_to_word_ids</span></code></a>(data,&nbsp;word_to_id)</td>
<td>Given a context (words) in list format and the vocabulary, Returns a list of IDs to represent the context.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#tensorlayer.files.word_ids_to_words" title="tensorlayer.files.word_ids_to_words"><code class="xref py py-obj docutils literal"><span class="pre">word_ids_to_words</span></code></a>(data,&nbsp;id_to_word)</td>
<td>Given a context (ids) in list format and the vocabulary, Returns a list of words to represent the context.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#tensorlayer.files.save_vocab" title="tensorlayer.files.save_vocab"><code class="xref py py-obj docutils literal"><span class="pre">save_vocab</span></code></a>(count[,&nbsp;name])</td>
<td>Save the vocabulary to a file so the model can be reloaded.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#tensorlayer.files.save_npz" title="tensorlayer.files.save_npz"><code class="xref py py-obj docutils literal"><span class="pre">save_npz</span></code></a>([save_dict,&nbsp;name])</td>
<td>Input parameters and the file name, save parameters into .npz file.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#tensorlayer.files.load_npz" title="tensorlayer.files.load_npz"><code class="xref py py-obj docutils literal"><span class="pre">load_npz</span></code></a>([path,&nbsp;name])</td>
<td>Load the parameters of a Model saved by tl.files.save_npz().</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#tensorlayer.files.assign_params" title="tensorlayer.files.assign_params"><code class="xref py py-obj docutils literal"><span class="pre">assign_params</span></code></a>(sess,&nbsp;params,&nbsp;network)</td>
<td>Assign the given parameters to the TensorLayer network.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#tensorlayer.files.npz_to_W_pdf" title="tensorlayer.files.npz_to_W_pdf"><code class="xref py py-obj docutils literal"><span class="pre">npz_to_W_pdf</span></code></a>([path,&nbsp;regx])</td>
<td>Convert the first weight matrix of .npz file to .pdf by using tl.visualize.W().</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#tensorlayer.files.save_any_to_npy" title="tensorlayer.files.save_any_to_npy"><code class="xref py py-obj docutils literal"><span class="pre">save_any_to_npy</span></code></a>([save_dict,&nbsp;name])</td>
<td>Save variables to .npy file.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#tensorlayer.files.save_any_to_npy" title="tensorlayer.files.save_any_to_npy"><code class="xref py py-obj docutils literal"><span class="pre">save_any_to_npy</span></code></a>([save_dict,&nbsp;name])</td>
<td>Save variables to .npy file.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#tensorlayer.files.load_file_list" title="tensorlayer.files.load_file_list"><code class="xref py py-obj docutils literal"><span class="pre">load_file_list</span></code></a>([path,&nbsp;regx])</td>
<td>Return a file list in a folder by given a path and regular expression.</td>
</tr>
</tbody>
</table>
<div class="section" id="load-dataset-functions">
<h2>Load dataset functions<a class="headerlink" href="#load-dataset-functions" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="tensorlayer.files.load_mnist_dataset">
<code class="descclassname">tensorlayer.files.</code><code class="descname">load_mnist_dataset</code><span class="sig-paren">(</span><em>shape=(-1</em>, <em>784)</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#load_mnist_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.load_mnist_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Automatically download MNIST dataset
and return the training, validation and test set with 50000, 10000 and 10000
digit images respectively.</p>
<dl class="docutils">
<dt>shape</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">tuple</span><dd>The shape of digit images</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">load_mnist_dataset</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">784</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="tensorlayer.files.load_cifar10_dataset">
<code class="descclassname">tensorlayer.files.</code><code class="descname">load_cifar10_dataset</code><span class="sig-paren">(</span><em>shape=(-1</em>, <em>32</em>, <em>32</em>, <em>3)</em>, <em>plotable=False</em>, <em>second=3</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#load_cifar10_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.load_cifar10_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with
6000 images per class. There are 50000 training images and 10000 test images.</p>
<p>The dataset is divided into five training batches and one test batch, each with
10000 images. The test batch contains exactly 1000 randomly-selected images from
each class. The training batches contain the remaining images in random order,
but some training batches may contain more images from one class than another.
Between them, the training batches contain exactly 5000 images from each class.</p>
<p># code references : <a class="reference external" href="https://teratail.com/questions/28932">https://teratail.com/questions/28932</a>
# data download link : <a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz">https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz</a></p>
<blockquote>
<div><a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></div></blockquote>
<dl class="docutils">
<dt>shape</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">tupe</span><dd>The shape of digit images: e.g. (-1, 3, 32, 32) , (-1, 32, 32, 3) , (-1, 32*32*3)</dd>
<dt>plotable</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">True, False</span><dd>Whether to plot some image examples.</dd>
<dt>second</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>If &#8216;plotable&#8217; is True, &#8216;second&#8217; is the display time.</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">load_cifar10_dataset</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">plotable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>CIFAR-10 images can only be display without color change under uint8.
&gt;&gt;&gt; X_train = np.asarray(X_train, dtype=np.uint8)
&gt;&gt;&gt; plt.ion()
&gt;&gt;&gt; fig = plt.figure(1232)
&gt;&gt;&gt; count = 1
&gt;&gt;&gt; for row in range(10):
&gt;&gt;&gt;     for col in range(10):
&gt;&gt;&gt;         a = fig.add_subplot(10, 10, count)
&gt;&gt;&gt;         plt.imshow(X_train[count-1], interpolation=&#8217;nearest&#8217;)
&gt;&gt;&gt;         plt.gca().xaxis.set_major_locator(plt.NullLocator())    # 不显示刻度(tick)
&gt;&gt;&gt;         plt.gca().yaxis.set_major_locator(plt.NullLocator())
&gt;&gt;&gt;         count = count + 1
&gt;&gt;&gt; plt.draw()
&gt;&gt;&gt; plt.pause(3)</p>
</dd></dl>

<dl class="function">
<dt id="tensorlayer.files.load_ptb_dataset">
<code class="descclassname">tensorlayer.files.</code><code class="descname">load_ptb_dataset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#load_ptb_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.load_ptb_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>PTB dataset is used in many LM papers, including &#8220;Empirical Evaluation
and Combination of Advanced Language Modeling Techniques&#8221;.</p>
<p>tensorflow.models.rnn.ptb import reader</p>
<p><a class="reference external" href="http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz">http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz</a></p>
</dd></dl>

<dl class="function">
<dt id="tensorlayer.files.load_matt_mahoney_text8_dataset">
<code class="descclassname">tensorlayer.files.</code><code class="descname">load_matt_mahoney_text8_dataset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#load_matt_mahoney_text8_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.load_matt_mahoney_text8_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Download a text file from Matt Mahoney&#8217;s website
if not present, and make sure it&#8217;s the right size.
Extract the first file enclosed in a zip file as a list of words.
The data can be used for testing Word Embedding.</p>
<dl class="docutils">
<dt>word_list</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a list</span><dd>a list of string (word).
e.g. [.... &#8216;their&#8217;, &#8216;families&#8217;, &#8216;who&#8217;, &#8216;were&#8217;, &#8216;expelled&#8217;, &#8216;from&#8217;, &#8216;jerusalem&#8217;, ...]</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">words</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">load_matt_mahoney_text8_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Data size&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="tensorlayer.files.load_imbd_dataset">
<code class="descclassname">tensorlayer.files.</code><code class="descname">load_imbd_dataset</code><span class="sig-paren">(</span><em>path='imdb.pkl'</em>, <em>nb_words=None</em>, <em>skip_top=0</em>, <em>maxlen=None</em>, <em>test_split=0.2</em>, <em>seed=113</em>, <em>start_char=1</em>, <em>oov_char=2</em>, <em>index_from=3</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#load_imbd_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.load_imbd_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Load IMDB dataset</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">load_imbd_dataset</span><span class="p">(</span>
<span class="gp">... </span>                                <span class="n">nb_words</span><span class="o">=</span><span class="mi">20000</span><span class="p">,</span> <span class="n">test_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X_train.shape&#39;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">... </span><span class="p">(</span><span class="mi">20000</span><span class="p">,)</span>  <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">62</span><span class="p">,</span> <span class="mi">74</span><span class="p">,</span> <span class="o">...</span> <span class="mi">1033</span><span class="p">,</span> <span class="mi">507</span><span class="p">,</span> <span class="mi">27</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="o">...</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">1053</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span><span class="o">..</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;y_train.shape&#39;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">... </span><span class="p">(</span><span class="mi">20000</span><span class="p">,)</span>  <span class="p">[</span><span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="o">...</span><span class="p">,</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>Modify from keras.
<a class="reference external" href="https://github.com/fchollet/keras/blob/master/keras/datasets/imdb.py">https://github.com/fchollet/keras/blob/master/keras/datasets/imdb.py</a></p>
</dd></dl>

</div>
<div class="section" id="vector-representations-of-words">
<h2>Vector representations of words<a class="headerlink" href="#vector-representations-of-words" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="tensorlayer.files.read_words">
<code class="descclassname">tensorlayer.files.</code><code class="descname">read_words</code><span class="sig-paren">(</span><em>filename</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#read_words"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.read_words" title="Permalink to this definition">¶</a></dt>
<dd><p>File to list format context.</p>
<blockquote>
<div><dl class="docutils">
<dt>filename</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a string</span><dd>a file path (like .txt file),</dd>
</dl>
<p>The context in a list, split by &#8216; &#8216; by default, and use &#8216;&lt;eos&gt;&#8217; to represent &#8216;</p>
</div></blockquote>
<dl class="docutils">
<dt>&#8216;.</dt>
<dd><p class="first">e.g. [... &#8216;how&#8217;, &#8216;useful&#8217;, &#8216;it&#8217;, &#8220;&#8216;s&#8221; ... ]</p>
<p class="last">tensorflow.models.rnn.ptb.reader</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorlayer.files.read_analogies_file">
<code class="descclassname">tensorlayer.files.</code><code class="descname">read_analogies_file</code><span class="sig-paren">(</span><em>eval_file='questions-words.txt'</em>, <em>word2id={}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#read_analogies_file"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.read_analogies_file" title="Permalink to this definition">¶</a></dt>
<dd><p>Reads through an analogy question file, return its id format.</p>
<dl class="docutils">
<dt>eval_data</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a string</span><dd>The file name.</dd>
<dt>word2id</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a dictionary</span><dd>Mapping words to unique IDs.</dd>
</dl>
<p>Returns:
questions: a [n, 4] numpy array containing the analogy question&#8217;s</p>
<blockquote>
<div>word ids.
questions_skipped: questions skipped due to unknown words.</div></blockquote>
<p>eval_file should be in this format :
: capital-common-countries
Athens Greece Baghdad Iraq
Athens Greece Bangkok Thailand
Athens Greece Beijing China
Athens Greece Berlin Germany
Athens Greece Bern Switzerland
Athens Greece Cairo Egypt
Athens Greece Canberra Australia
Athens Greece Hanoi Vietnam
Athens Greece Havana Cuba
...</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">words</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">load_matt_mahoney_text8_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">reverse_dictionary</span> <span class="o">=</span>                 <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">build_words_dataset</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">vocabulary_size</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">analogy_questions</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">read_analogies_file</span><span class="p">(</span>                 <span class="n">eval_file</span><span class="o">=</span><span class="s1">&#39;questions-words.txt&#39;</span><span class="p">,</span> <span class="n">word2id</span><span class="o">=</span><span class="n">dictionary</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">analogy_questions</span><span class="p">)</span>
<span class="gp">... </span><span class="p">[[</span> <span class="mi">3068</span>  <span class="mi">1248</span>  <span class="mi">7161</span>  <span class="mi">1581</span><span class="p">]</span>
<span class="gp">... </span><span class="p">[</span> <span class="mi">3068</span>  <span class="mi">1248</span> <span class="mi">28683</span>  <span class="mi">5642</span><span class="p">]</span>
<span class="gp">... </span><span class="p">[</span> <span class="mi">3068</span>  <span class="mi">1248</span>  <span class="mi">3878</span>   <span class="mi">486</span><span class="p">]</span>
<span class="gp">... </span><span class="o">...</span><span class="p">,</span>
<span class="gp">... </span><span class="p">[</span> <span class="mi">1216</span>  <span class="mi">4309</span> <span class="mi">19982</span> <span class="mi">25506</span><span class="p">]</span>
<span class="gp">... </span><span class="p">[</span> <span class="mi">1216</span>  <span class="mi">4309</span>  <span class="mi">3194</span>  <span class="mi">8650</span><span class="p">]</span>
<span class="gp">... </span><span class="p">[</span> <span class="mi">1216</span>  <span class="mi">4309</span>   <span class="mi">140</span>   <span class="mi">312</span><span class="p">]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="tensorlayer.files.build_vocab">
<code class="descclassname">tensorlayer.files.</code><code class="descname">build_vocab</code><span class="sig-paren">(</span><em>data</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#build_vocab"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.build_vocab" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Build vocabulary.</dt>
<dd>Given the context in list format
Return the vocabulary, which is a dictionary for word to id.
e.g. {&#8216;campbell&#8217;: 2587, &#8216;atlantic&#8217;: 2247, &#8216;aoun&#8217;: 6746 .... }</dd>
</dl>
<dl class="docutils">
<dt>data</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a list of string</span><dd>the context in list format</dd>
</dl>
<dl class="docutils">
<dt>word_to_id</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a dictionary</span><dd>mapping words to unique IDs.
e.g. {&#8216;campbell&#8217;: 2587, &#8216;atlantic&#8217;: 2247, &#8216;aoun&#8217;: 6746 .... }</dd>
</dl>
<p>tensorflow.models.rnn.ptb.reader</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span> <span class="o">+</span> <span class="s1">&#39;/simple-examples/data&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;ptb.train.txt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">word_to_id</span> <span class="o">=</span> <span class="n">build_vocab</span><span class="p">(</span><span class="n">read_txt_words</span><span class="p">(</span><span class="n">train_path</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="tensorlayer.files.build_reverse_dictionary">
<code class="descclassname">tensorlayer.files.</code><code class="descname">build_reverse_dictionary</code><span class="sig-paren">(</span><em>word_to_id</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#build_reverse_dictionary"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.build_reverse_dictionary" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a dictionary for converting word to integer id.
Returns a reverse dictionary for converting a id to word.</p>
</dd></dl>

<dl class="function">
<dt id="tensorlayer.files.build_words_dataset">
<code class="descclassname">tensorlayer.files.</code><code class="descname">build_words_dataset</code><span class="sig-paren">(</span><em>words</em>, <em>vocabulary_size=50000</em>, <em>printable=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#build_words_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.build_words_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Build the words dictionary and replace rare words with &#8216;UNK&#8217; token.
The most common word has the smallest integer id.</p>
<dl class="docutils">
<dt>words</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a list of string or byte</span><dd>The context in list format</dd>
<dt>vocabulary_size</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">an int</span><dd>The maximum vocabulary size, limiting the vocabulary size.
Then the script replaces rare words with &#8216;UNK&#8217; token.</dd>
<dt>printable</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">boolen</span><dd>Whether to print the read vocabulary size of the given words.</dd>
</dl>
<dl class="docutils">
<dt>data</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a list of integer</span><dd>The context in a list of ids</dd>
<dt>count</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a list of tuple and list</span><dd><p class="first">count[0] is a list : the number of rare words
count[1:] are tuples : the number of occurrence of each word
e.g. [[&#8216;UNK&#8217;, 418391], (b&#8217;the&#8217;, 1061396), (b&#8217;of&#8217;, 593677),</p>
<blockquote class="last">
<div>(b&#8217;and&#8217;, 416629), (b&#8217;one&#8217;, 411764)]</div></blockquote>
</dd>
<dt>dictionary</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a dictionary</span><dd>word_to_id, mapping words to unique IDs.</dd>
<dt>reverse_dictionary</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a dictionary</span><dd>id_to_word, mapping id to unique word.</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">words</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">load_matt_mahoney_text8_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vocabulary_size</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">reverse_dictionary</span> <span class="o">=</span>     <span class="o">...</span>     <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">build_words_dataset</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">vocabulary_size</span><span class="p">)</span>
</pre></div>
</div>
<p>tensorflow/examples/tutorials/word2vec/word2vec_basic.py</p>
</dd></dl>

<dl class="function">
<dt id="tensorlayer.files.words_to_word_ids">
<code class="descclassname">tensorlayer.files.</code><code class="descname">words_to_word_ids</code><span class="sig-paren">(</span><em>data</em>, <em>word_to_id</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#words_to_word_ids"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.words_to_word_ids" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a context (words) in list format and the vocabulary,
Returns a list of IDs to represent the context.</p>
<dl class="docutils">
<dt>data</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a list of string or byte</span><dd>the context in list format</dd>
<dt>word_to_id</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a dictionary</span><dd>mapping words to unique IDs.</dd>
</dl>
<p>A list of IDs to represent the context.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">words</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">load_matt_mahoney_text8_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vocabulary_size</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">reverse_dictionary</span> <span class="o">=</span>     <span class="o">...</span>         <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">build_words_dataset</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">vocabulary_size</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="s1">&#39;hello&#39;</span><span class="p">,</span> <span class="n">b</span><span class="s1">&#39;how&#39;</span><span class="p">,</span> <span class="n">b</span><span class="s1">&#39;are&#39;</span><span class="p">,</span> <span class="n">b</span><span class="s1">&#39;you&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ids</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">words_to_word_ids</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">word_ids_to_words</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">reverse_dictionary</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>
<span class="gp">... </span><span class="p">[</span><span class="mi">6434</span><span class="p">,</span> <span class="mi">311</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">207</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
<span class="gp">... </span><span class="p">[</span><span class="n">b</span><span class="s1">&#39;hello&#39;</span><span class="p">,</span> <span class="n">b</span><span class="s1">&#39;how&#39;</span><span class="p">,</span> <span class="n">b</span><span class="s1">&#39;are&#39;</span><span class="p">,</span> <span class="n">b</span><span class="s1">&#39;you&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>tensorflow.models.rnn.ptb.reader</p>
</dd></dl>

<dl class="function">
<dt id="tensorlayer.files.word_ids_to_words">
<code class="descclassname">tensorlayer.files.</code><code class="descname">word_ids_to_words</code><span class="sig-paren">(</span><em>data</em>, <em>id_to_word</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#word_ids_to_words"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.word_ids_to_words" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a context (ids) in list format and the vocabulary,
Returns a list of words to represent the context.</p>
<dl class="docutils">
<dt>data</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a list of integer</span><dd>the context in list format</dd>
<dt>id_to_word</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a dictionary</span><dd>mapping id to unique word.</dd>
</dl>
<p>A list of string or byte to represent the context.</p>
<p>see words_to_word_ids</p>
</dd></dl>

<dl class="function">
<dt id="tensorlayer.files.save_vocab">
<code class="descclassname">tensorlayer.files.</code><code class="descname">save_vocab</code><span class="sig-paren">(</span><em>count</em>, <em>name='vocab.txt'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#save_vocab"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.save_vocab" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the vocabulary to a file so the model can be reloaded.</p>
<dl class="docutils">
<dt>count</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a list of tuple and list</span><dd><p class="first">count[0] is a list : the number of rare words
count[1:] are tuples : the number of occurrence of each word
e.g. [[&#8216;UNK&#8217;, 418391], (b&#8217;the&#8217;, 1061396), (b&#8217;of&#8217;, 593677),</p>
<blockquote class="last">
<div>(b&#8217;and&#8217;, 416629), (b&#8217;one&#8217;, 411764)]</div></blockquote>
</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">words</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">load_matt_mahoney_text8_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vocabulary_size</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">reverse_dictionary</span> <span class="o">=</span>                 <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">build_words_dataset</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">vocabulary_size</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">save_vocab</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;vocab_text8.txt&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vocab_text8</span><span class="o">.</span><span class="n">txt</span>
<span class="gp">... </span><span class="n">UNK</span> <span class="mi">418391</span>
<span class="gp">... </span><span class="n">the</span> <span class="mi">1061396</span>
<span class="gp">... </span><span class="n">of</span> <span class="mi">593677</span>
<span class="gp">... </span><span class="ow">and</span> <span class="mi">416629</span>
<span class="gp">... </span><span class="n">one</span> <span class="mi">411764</span>
<span class="gp">... </span><span class="ow">in</span> <span class="mi">372201</span>
<span class="gp">... </span><span class="n">a</span> <span class="mi">325873</span>
<span class="gp">... </span><span class="n">to</span> <span class="mi">316376</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="load-and-save-network">
<h2>Load and save network<a class="headerlink" href="#load-and-save-network" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="tensorlayer.files.save_npz">
<code class="descclassname">tensorlayer.files.</code><code class="descname">save_npz</code><span class="sig-paren">(</span><em>save_dict={}</em>, <em>name='model.npz'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#save_npz"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.save_npz" title="Permalink to this definition">¶</a></dt>
<dd><p>Input parameters and the file name, save parameters into .npz file. Use tl.utils.load_npz() to restore.</p>
<dl class="docutils">
<dt>save_dict</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a dictionary</span><dd>Parameters want to be saved.</dd>
<dt>name</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a string or None</span><dd>The name of the .npz file.</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">save_npz</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">all_params</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;model_test.npz&#39;</span><span class="p">)</span>
<span class="gp">... </span><span class="n">File</span> <span class="n">saved</span> <span class="n">to</span><span class="p">:</span> <span class="n">model_test</span><span class="o">.</span><span class="n">npz</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">load_params</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">load_npz</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;model_test.npz&#39;</span><span class="p">)</span>
<span class="gp">... </span><span class="n">Loading</span> <span class="n">param0</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">800</span><span class="p">)</span>
<span class="gp">... </span><span class="n">Loading</span> <span class="n">param1</span><span class="p">,</span> <span class="p">(</span><span class="mi">800</span><span class="p">,)</span>
<span class="gp">... </span><span class="n">Loading</span> <span class="n">param2</span><span class="p">,</span> <span class="p">(</span><span class="mi">800</span><span class="p">,</span> <span class="mi">800</span><span class="p">)</span>
<span class="gp">... </span><span class="n">Loading</span> <span class="n">param3</span><span class="p">,</span> <span class="p">(</span><span class="mi">800</span><span class="p">,)</span>
<span class="gp">... </span><span class="n">Loading</span> <span class="n">param4</span><span class="p">,</span> <span class="p">(</span><span class="mi">800</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">... </span><span class="n">Loading</span> <span class="n">param5</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">put</span> <span class="n">parameters</span> <span class="n">into</span> <span class="n">a</span> <span class="n">TensorLayer</span> <span class="n">network</span><span class="p">,</span> <span class="n">please</span> <span class="n">see</span> <span class="n">assign_params</span><span class="p">()</span>
</pre></div>
</div>
<p><a class="reference external" href="http://stackoverflow.com/questions/22315595/saving-dictionary-of-header-information-using-numpy-savez">http://stackoverflow.com/questions/22315595/saving-dictionary-of-header-information-using-numpy-savez</a></p>
</dd></dl>

<dl class="function">
<dt id="tensorlayer.files.load_npz">
<code class="descclassname">tensorlayer.files.</code><code class="descname">load_npz</code><span class="sig-paren">(</span><em>path=''</em>, <em>name='model.npz'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#load_npz"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.load_npz" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the parameters of a Model saved by tl.files.save_npz().</p>
<dl class="docutils">
<dt>path</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a string</span><dd>Folder path to .npz file.</dd>
<dt>name</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a string or None</span><dd>The name of the .npz file.</dd>
</dl>
<dl class="docutils">
<dt>params</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">list</span><dd>A list of parameters in order.</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">see</span> <span class="n">save_npz</span> <span class="ow">and</span> <span class="n">assign_params</span>
</pre></div>
</div>
<p><a class="reference external" href="http://stackoverflow.com/questions/22315595/saving-dictionary-of-header-information-using-numpy-savez">http://stackoverflow.com/questions/22315595/saving-dictionary-of-header-information-using-numpy-savez</a></p>
</dd></dl>

<dl class="function">
<dt id="tensorlayer.files.assign_params">
<code class="descclassname">tensorlayer.files.</code><code class="descname">assign_params</code><span class="sig-paren">(</span><em>sess</em>, <em>params</em>, <em>network</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#assign_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.assign_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Assign the given parameters to the TensorLayer network.</p>
<p>sess : TensorFlow Session
params : list</p>
<blockquote>
<div>A list of parameters in order.</div></blockquote>
<dl class="docutils">
<dt>network</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier"><code class="xref py py-class docutils literal"><span class="pre">Layer</span></code> class</span><dd>The network to be assigned</dd>
</dl>
<p>... Save your network as follow:
&gt;&gt;&gt; tl.files.save_npz(network.all_params, name=&#8217;model_test.npz&#8217;)
&gt;&gt;&gt; network.print_params()
...
... Next time, load and assign your network as follow:
&gt;&gt;&gt; sess.run(tf.initialize_all_variables()) # re-initialize, then save and assign
&gt;&gt;&gt; load_params = tl.files.load_npz(name=&#8217;model_test.npz&#8217;)
&gt;&gt;&gt; tl.files.assign_params(sess, load_params, network)
&gt;&gt;&gt; network.print_params()</p>
<p><a class="reference external" href="http://stackoverflow.com/questions/34220532/how-to-assign-value-to-a-tensorflow-variable">http://stackoverflow.com/questions/34220532/how-to-assign-value-to-a-tensorflow-variable</a></p>
</dd></dl>

</div>
<div class="section" id="load-and-save-variables">
<h2>Load and save variables<a class="headerlink" href="#load-and-save-variables" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="tensorlayer.files.save_any_to_npy">
<code class="descclassname">tensorlayer.files.</code><code class="descname">save_any_to_npy</code><span class="sig-paren">(</span><em>save_dict={}</em>, <em>name='any.npy'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#save_any_to_npy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.save_any_to_npy" title="Permalink to this definition">¶</a></dt>
<dd><p>Save variables to .npy file.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">save_any_to_npy</span><span class="p">(</span><span class="n">save_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;data&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span><span class="s1">&#39;b&#39;</span><span class="p">]},</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test.npy&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">load_npy_to_any</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;test.npy&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">... </span><span class="p">{</span><span class="s1">&#39;data&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span><span class="s1">&#39;b&#39;</span><span class="p">]}</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">tensorlayer.files.</code><code class="descname">save_any_to_npy</code><span class="sig-paren">(</span><em>save_dict={}</em>, <em>name='any.npy'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#save_any_to_npy"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Save variables to .npy file.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">save_any_to_npy</span><span class="p">(</span><span class="n">save_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;data&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span><span class="s1">&#39;b&#39;</span><span class="p">]},</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test.npy&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">load_npy_to_any</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;test.npy&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">... </span><span class="p">{</span><span class="s1">&#39;data&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span><span class="s1">&#39;b&#39;</span><span class="p">]}</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="visualizing-npz-file">
<h2>Visualizing npz file<a class="headerlink" href="#visualizing-npz-file" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="tensorlayer.files.npz_to_W_pdf">
<code class="descclassname">tensorlayer.files.</code><code class="descname">npz_to_W_pdf</code><span class="sig-paren">(</span><em>path=None</em>, <em>regx='w1pre_[0-9]+\\.(npz)'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#npz_to_W_pdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.npz_to_W_pdf" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert the first weight matrix of .npz file to .pdf by using tl.visualize.W().</p>
<dl class="docutils">
<dt>path</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a string or None</span><dd>A folder path to npz files.</dd>
<dt>regx</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a string</span><dd>Regx for the file name.</dd>
</dl>
<p>... convert the first weight matrix of w1_pre...npz file to w1_pre...pdf.
&gt;&gt;&gt; tl.files.npz_to_W_pdf(path=&#8217;/Users/.../npz_file/&#8217;, regx=&#8217;w1pre_[0-9]+.(npz)&#8217;)</p>
</dd></dl>

</div>
<div class="section" id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="tensorlayer.files.load_file_list">
<code class="descclassname">tensorlayer.files.</code><code class="descname">load_file_list</code><span class="sig-paren">(</span><em>path=None</em>, <em>regx='\\.npz'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorlayer/files.html#load_file_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorlayer.files.load_file_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a file list in a folder by given a path and regular expression.</p>
<dl class="docutils">
<dt>path</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a string or None</span><dd>A folder path.</dd>
<dt>regx</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">a string</span><dd>The regx of file name.</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">file_list</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">load_file_list</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">regx</span><span class="o">=</span><span class="s1">&#39;w1pre_[0-9]+\.(npz)&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="utils.html" class="btn btn-neutral float-right" title="tensorlayer.utils" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="visualize.html" class="btn btn-neutral" title="tensorlayer.visualize" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, TensorLayer contributors.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>