{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "import time\n",
    "from keras import backend as K\n",
    "from keras.layers import *\n",
    "from tensorlayer.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Keras could use Tensorflow or theano as the backend, but the default setting is tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load or Download MNIST > data/mnist/\n",
      "Downloading train-images-idx3-ubyte.gz...100%\n",
      "Succesfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "data/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading train-labels-idx1-ubyte.gz...113%\n",
      "Succesfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Downloading t10k-images-idx3-ubyte.gz...100%\n",
      "Succesfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading t10k-labels-idx1-ubyte.gz...180%\n",
      "Succesfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test =tl.files.load_mnist_dataset(shape=(-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.int64, shape=[None,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keras_block(x):\n",
    "    x = Dropout(0.8)(x)\n",
    "    x = Dense(800, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(800, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    logits = Dense(10, activation='linear')(x)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [TL] InputLayer  input: (?, 784)\n",
      "  [TL] KerasLayer keras: <function keras_block at 0x0000014CE9E96620>\n",
      "       This API will be removed, please use LambdaLayer instead.\n"
     ]
    }
   ],
   "source": [
    "network = InputLayer(x, name='input')\n",
    "network = KerasLayer(network, keras_layer=keras_block, name='keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = network.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'keras/dense_3/BiasAdd:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  param   0: (784, 800)         keras/dense_1/kernel:0\n",
      "  param   1: (800,)             keras/dense_1/bias:0\n",
      "  param   2: (800, 800)         keras/dense_2/kernel:0\n",
      "  param   3: (800,)             keras/dense_2/bias:0\n",
      "  param   4: (800, 10)          keras/dense_3/kernel:0\n",
      "  param   5: (10,)              keras/dense_3/bias:0\n",
      "  num of params: 1276810\n"
     ]
    }
   ],
   "source": [
    "network.print_params(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  layer 0: Tensor(\"keras/dense_3/BiasAdd:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "network.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tl.cost.cross_entropy(y, y_, 'cost')\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), y_)\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 200\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_params = network.all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999,\n",
    "    epsilon=1e-08, use_locking=False).minimize(cost, var_list=train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tl.layers.initialize_global_variables(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We began to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 200 took 12.526583s\n",
      "   train loss: 0.815532\n",
      "   train acc: 0.822456\n",
      "   val loss: 0.776519\n",
      "   val acc: 0.843450\n",
      "Epoch 2 of 200 took 12.771707s\n",
      "   train loss: 0.591552\n",
      "   train acc: 0.855929\n",
      "   val loss: 0.551409\n",
      "   val acc: 0.871695\n",
      "Epoch 3 of 200 took 11.570901s\n",
      "   train loss: 0.524391\n",
      "   train acc: 0.874359\n",
      "   val loss: 0.485615\n",
      "   val acc: 0.887420\n",
      "Epoch 4 of 200 took 11.518147s\n",
      "   train loss: 0.484785\n",
      "   train acc: 0.877344\n",
      "   val loss: 0.447274\n",
      "   val acc: 0.888922\n",
      "Epoch 5 of 200 took 11.721315s\n",
      "   train loss: 0.453363\n",
      "   train acc: 0.891707\n",
      "   val loss: 0.417462\n",
      "   val acc: 0.901242\n",
      "Epoch 6 of 200 took 12.269288s\n",
      "   train loss: 0.426012\n",
      "   train acc: 0.895272\n",
      "   val loss: 0.390113\n",
      "   val acc: 0.907352\n",
      "Epoch 7 of 200 took 11.807560s\n",
      "   train loss: 0.403468\n",
      "   train acc: 0.897256\n",
      "   val loss: 0.369989\n",
      "   val acc: 0.910156\n",
      "Epoch 8 of 200 took 11.738737s\n",
      "   train loss: 0.386020\n",
      "   train acc: 0.902544\n",
      "   val loss: 0.354183\n",
      "   val acc: 0.913562\n",
      "Epoch 9 of 200 took 12.013738s\n",
      "   train loss: 0.365295\n",
      "   train acc: 0.910657\n",
      "   val loss: 0.334254\n",
      "   val acc: 0.920473\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    start_time = time.time()\n",
    "    ## Training\n",
    "    for X_train_a, y_train_a in tl.iterate.minibatches(\n",
    "                                X_train, y_train, batch_size, shuffle=True):\n",
    "        _, _ = sess.run([cost, train_op], feed_dict={x: X_train_a, y_: y_train_a,\n",
    "                                K.learning_phase(): 1})\n",
    "\n",
    "    print(\"Epoch %d of %d took %fs\" % (epoch + 1, n_epoch, time.time() - start_time))\n",
    "    ## Evaluation\n",
    "    train_loss, train_acc, n_batch = 0, 0, 0\n",
    "    for X_train_a, y_train_a in tl.iterate.minibatches(\n",
    "                            X_train, y_train, batch_size, shuffle=False):\n",
    "        err, ac = sess.run([cost, acc], feed_dict={x: X_train_a, y_: y_train_a,\n",
    "                                K.learning_phase(): 0})\n",
    "        train_loss += err; train_acc += ac; n_batch += 1\n",
    "    print(\"   train loss: %f\" % (train_loss/ n_batch))\n",
    "    print(\"   train acc: %f\" % (train_acc/ n_batch))\n",
    "    val_loss, val_acc, n_batch = 0, 0, 0\n",
    "    for X_val_a, y_val_a in tl.iterate.minibatches(\n",
    "                                X_val, y_val, batch_size, shuffle=False):\n",
    "        err, ac = sess.run([cost, acc], feed_dict={x: X_val_a, y_: y_val_a,\n",
    "                                K.learning_phase(): 0})\n",
    "        val_loss += err; val_acc += ac; n_batch += 1\n",
    "    print(\"   val loss: %f\" % (val_loss/ n_batch))\n",
    "    print(\"   val acc: %f\" % (val_acc/ n_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit\n",
    "\n",
    "Credit goes to [TensorLayer Example](https://github.com/zsdonghao/tensorlayer/tree/master/example) for the majority of this code. I've merely create a jupyter notebook to make it more readable."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
